{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualizations\n",
    "\n",
    "To create the data visualizations I had to extract from the tables the values of some variables, especially the count of the values inserted in the different categories, for example archive, library, place, shape, support and type, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Value  Count\n",
      "0                       Archivio Bonsanti     49\n",
      "1  Archivio Biblioteca Nazionale Centrale     12\n",
      "2                       Archivio Garzanti     89\n",
      "3                          Archivio Gelli     47\n",
      "4                       Archivio Liberati    585\n",
      "5             Archivio Centro Manoscritti      4\n",
      "6         Archivio Biblioteca Trivulziana    797\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Path to your file conta/Users/martinapensalfini/Desktop/gadda/mergecolumntipo.jsonining the JSON-like data\n",
    "file_path = 'mergecolumntipo.json'\n",
    "\n",
    "# Read the content of the file\n",
    "with open(file_path, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Pattern to match values after \"archivio:\" and before \"/\"\n",
    "pattern = r'archivio:\\s(.*?)(?= \\/)'\n",
    "\n",
    "# Extracting values matching the pattern from the \"Archival Description\" field of each item\n",
    "matches = []\n",
    "for item in json_data:\n",
    "    archival_description = item.get(\"Archival Description\", \"\")\n",
    "    match = re.search(pattern, archival_description)\n",
    "    if match:\n",
    "        matches.append(match.group(1))\n",
    "\n",
    "# If no matches were found\n",
    "if not matches:\n",
    "    print(\"No matches found for the pattern 'archivio:' before '/'\")\n",
    "else:\n",
    "    # Counting occurrences of each value\n",
    "    value_counts = Counter(matches)\n",
    "\n",
    "    # Create a DataFrame from the value counts\n",
    "    df = pd.DataFrame(value_counts.items(), columns=['Value', 'Count'])\n",
    "\n",
    "    # Display the DataFrame\n",
    "    print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then each result was saved as an Excel spreadsheet for commodity as this was the format required by *Fluorish* to later create the data visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"archiviografico.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting example was also the fact that aside from execuing a simple count of values, I also counted the count of a certain category (in this case *thematic cards*) per archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Value                         Archivio  Count\n",
      "0          AppUni                Archivio Bonsanti      9\n",
      "1         QuaScol                Archivio Bonsanti     12\n",
      "2         AppGue                 Archivio Bonsanti      1\n",
      "3      AppLetTed                 Archivio Bonsanti      6\n",
      "4           Cont                 Archivio Bonsanti      7\n",
      "..            ...                              ...    ...\n",
      "244        TestIn  Archivio Biblioteca Trivulziana      5\n",
      "245  LetTrinnanzi  Archivio Biblioteca Trivulziana      4\n",
      "246      Opere IV  Archivio Biblioteca Trivulziana      6\n",
      "247    LetBassani  Archivio Biblioteca Trivulziana      2\n",
      "248           Let  Archivio Biblioteca Trivulziana     42\n",
      "\n",
      "[249 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "\n",
    "file_path = 'mergecolumntipo.json'\n",
    "\n",
    "# Read the content of the file\n",
    "with open(file_path, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Create a defaultdict to store values for 'schede tematiche' grouped by 'archivio'\n",
    "archivio_schede = defaultdict(list)\n",
    "\n",
    "# Pattern to match values after \"schede tematiche:\" until the new line\n",
    "pattern = r'schede tematiche:\\s(.*?)(?=\\n)'\n",
    "\n",
    "# Extracting values for 'schede tematiche' and grouping them by 'archivio'\n",
    "for item in json_data:\n",
    "    archivio = re.search(r'archivio:\\s(.*?)(?= \\/)', item.get(\"Archival Description\", \"\")).group(1)\n",
    "    schede_match = re.findall(pattern, item.get(\"Internal Description\", \"\"))\n",
    "    for schede in schede_match:\n",
    "        values = schede.split(', ')\n",
    "        archivio_schede[archivio].extend(values)\n",
    "\n",
    "# Counting occurrences of each value for 'schede tematiche' grouped by 'archivio'\n",
    "archivio_counts = {archivio: Counter(values) for archivio, values in archivio_schede.items()}\n",
    "\n",
    "# Create a list to store DataFrame rows\n",
    "data = []\n",
    "\n",
    "# Populate the list with rows containing 'Value', 'Archivio', and 'Count'\n",
    "for archivio, counts in archivio_counts.items():\n",
    "    for value, count in counts.items():\n",
    "        data.append({'Value': value, 'Archivio': archivio, 'Count': count})\n",
    "\n",
    "# Create a DataFrame from the list of rows\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"schedetematiche.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/martinapensalfini/Desktop/gadda/countgadda.ipynb Cella 7\u001b[0m line \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/martinapensalfini/Desktop/gadda/countgadda.ipynb#X10sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# Extracting values for 'luogo' and grouping them by 'archivio'\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/martinapensalfini/Desktop/gadda/countgadda.ipynb#X10sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m json_data:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/martinapensalfini/Desktop/gadda/countgadda.ipynb#X10sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     archivio \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39;49msearch(\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39marchivio:\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39ms(.*?)(?= \u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39m/)\u001b[39;49m\u001b[39m'\u001b[39;49m, item\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mInternal Description\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m))\u001b[39m.\u001b[39;49mgroup(\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/martinapensalfini/Desktop/gadda/countgadda.ipynb#X10sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     luogo_match \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39mfindall(pattern, item\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mInternal Description\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/martinapensalfini/Desktop/gadda/countgadda.ipynb#X10sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     archivio_luogo[archivio]\u001b[39m.\u001b[39mextend(luogo_match)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "\n",
    "file_path = 'mergecolumntipo.json'\n",
    "\n",
    "# Read the content of the file\n",
    "with open(file_path, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Create a defaultdict to store values for 'luogo' grouped by 'archivio'\n",
    "archivio_luogo = defaultdict(list)\n",
    "\n",
    "# Pattern to match values after \"luogo:\" until the new line\n",
    "pattern = r'luogo:\\s(.*?)(?=\\n)'\n",
    "\n",
    "# Extracting values for 'luogo' and grouping them by 'archivio'\n",
    "for item in json_data:\n",
    "    archivio = re.search(r'archivio:\\s(.*?)(?= \\/)', item.get(\"Internal Description\", \"\")).group(1)\n",
    "    luogo_match = re.findall(pattern, item.get(\"Internal Description\", \"\"))\n",
    "    archivio_luogo[archivio].extend(luogo_match)\n",
    "\n",
    "# Counting occurrences of each value for 'luogo' grouped by 'archivio'\n",
    "archivio_counts = {archivio: Counter(values) for archivio, values in archivio_luogo.items()}\n",
    "\n",
    "# Create a list to store DataFrame rows\n",
    "data = []\n",
    "\n",
    "# Populate the list with rows containing 'Value', 'Archivio', and 'Count'\n",
    "for archivio, counts in archivio_counts.items():\n",
    "    for value, count in counts.items():\n",
    "        data.append({'Value': value, 'Archivio': archivio, 'Count': count})\n",
    "\n",
    "# Create a DataFrame from the list of rows\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"luogoarchivio.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Value   Library  Count\n",
      "0           M         M     21\n",
      "1         RaI         M      1\n",
      "2           T         M      1\n",
      "3          GL        GL      8\n",
      "4         GGP       GGP     15\n",
      "..        ...       ...    ...\n",
      "136  Opere I   Opere I       1\n",
      "137       QPL       QPL      8\n",
      "138       LiM       LiM      1\n",
      "139  Opere IV  Opere IV      6\n",
      "140      NoID      NoID      1\n",
      "\n",
      "[141 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "\n",
    "file_path = 'mergecolumntipo.json'\n",
    "\n",
    "# Read the content of the file\n",
    "with open(file_path, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Create a defaultdict to store values for 'schede tematiche' grouped by 'library'\n",
    "library_scheduled = defaultdict(list)\n",
    "\n",
    "# Pattern to match values after \"library:\" until the new line\n",
    "pattern = r'library:\\s(.*?)(?=\\n|$)'\n",
    "\n",
    "# Extracting values for 'schede tematiche' and grouping them by 'library'\n",
    "for item in json_data:\n",
    "    library_match = re.search(pattern, item.get(\"Internal Description\", \"\"))\n",
    "    if library_match:\n",
    "        library_values = library_match.group(1).split(', ')\n",
    "        scheduled_match = re.findall(pattern, item.get(\"Internal Description\", \"\"))\n",
    "        for library in library_values:\n",
    "            for scheduled in scheduled_match:\n",
    "                values = scheduled.split(', ')\n",
    "                library_scheduled[library].extend(values)\n",
    "\n",
    "# Counting occurrences of each value for 'schede tematiche' grouped by 'library'\n",
    "library_counts = {library: Counter(values) for library, values in library_scheduled.items()}\n",
    "\n",
    "# Create a list to store DataFrame rows\n",
    "data = []\n",
    "\n",
    "# Populate the list with rows containing 'Value', 'Library', and 'Count'\n",
    "for library, counts in library_counts.items():\n",
    "    for value, count in counts.items():\n",
    "        data.append({'Value': value, 'Library': library, 'Count': count})\n",
    "\n",
    "# Create a DataFrame from the list of rows\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"archiviobiblioteca.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Value  Count\n",
      "0                    Celle      4\n",
      "1                   Milano    100\n",
      "2                     Roma    101\n",
      "3                   Genova      7\n",
      "4             Buenos Aires     11\n",
      "5                  Firenze     35\n",
      "6                    Siena      1\n",
      "7                  Venezia     11\n",
      "8                    Parma      2\n",
      "9                    Capri      1\n",
      "10                 Bergamo      9\n",
      "11                 Chianti      1\n",
      "12           Isola di Rodi      1\n",
      "13                    Zara      1\n",
      "14                 Tripoli      4\n",
      "15    S. Margherita Ligure      1\n",
      "16                 Longone     16\n",
      "17                  Stresa      1\n",
      "18            Cavalcaselle      1\n",
      "19                Sirmione      1\n",
      "20  S.ta Margherita Ligure      1\n",
      "21       Cortina dâ€™Ampezzo      1\n",
      "22                   Pocol      1\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Path to your file containing the JSON-like data\n",
    "file_path = 'mergecolumntipo.json'\n",
    "\n",
    "# Read the content of the file\n",
    "with open(file_path, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Pattern to match values after \"luogo:\" within the \"Internal Description\" field\n",
    "pattern = r'luogo:\\s(.*?)(?:\\n|$)'\n",
    "\n",
    "# Extracting values matching the pattern from the \"Internal Description\" field of each item\n",
    "matches = []\n",
    "for item in json_data:\n",
    "    internal_description = item.get(\"Internal Description\", \"\")\n",
    "    match = re.search(pattern, internal_description)\n",
    "    if match:\n",
    "        matches.append(match.group(1))\n",
    "\n",
    "# If no matches were found\n",
    "if not matches:\n",
    "    print(\"No matches found for the pattern 'luogo:' in the 'Internal Description' field.\")\n",
    "else:\n",
    "    # Counting occurrences of each value\n",
    "    value_counts = Counter(matches)\n",
    "\n",
    "    # Create a list to store DataFrame rows\n",
    "    data = [{'Value': value, 'Count': count} for value, count in value_counts.items()]\n",
    "\n",
    "    # Create a DataFrame from the list of rows\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"luoghigrafico.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this specific case, I also had to keep separated the values for the thematic cards regarding the themes and the works. And in some cases I actually operated a manual action on them as it was far more precise and useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other Values DataFrame saved to: /Users/martinapensalfini/Desktop/gadda/other_values.xlsx\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# Path to your file containing the JSON-like data\n",
    "file_path = 'mergecolumntipo.json'\n",
    "\n",
    "# Read the content of the file\n",
    "with open(file_path, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Create a defaultdict to store values for 'schede tematiche' grouped by 'archivio'\n",
    "archivio_schede = defaultdict(list)\n",
    "\n",
    "# Pattern to match values after \"schede tematiche:\" until the new line\n",
    "pattern = r'schede tematiche:\\s(.*?)(?=\\n)'\n",
    "\n",
    "# Extracting values for 'schede tematiche' and grouping them by 'archivio'\n",
    "for item in json_data:\n",
    "    archivio = re.search(r'archivio:\\s(.*?)(?= \\/)', item.get(\"Archival Description\", \"\")).group(1)\n",
    "    schede_match = re.findall(pattern, item.get(\"Internal Description\", \"\"))\n",
    "    for schede in schede_match:\n",
    "        values = schede.split(', ')\n",
    "        archivio_schede[archivio].extend(values)\n",
    "\n",
    "# Counting occurrences of each value for 'schede tematiche' grouped by 'archivio'\n",
    "archivio_counts = {archivio: Counter(values) for archivio, values in archivio_schede.items()}\n",
    "\n",
    "# Create a list to store DataFrame rows for specified values and others\n",
    "specified_values = [\"AG\", \"AS\", \"AZ\",\"DM\", \"DG\", \"EP67\", \"EP\", \"GGP\", \"A\", \"GB\", \"HJ\", \"LdF\",\"M\", \"MdS\", \"SF\", \"VM\", \"CdU\", \"GASP\", \"PdO\", \"PLF\", \"TO\", \"TE\", \"L'A\", \"CR\", \"CdD\", \"GG\", \"MdF\", \"M\", \"MM\", \"VS\", \"Biz\", \"MdI\", \"NS\", \"NDF\", \"DT\", \"P\", \"QP\", \"RD\", \"RAI\", \"RI\", \"Opere I\", \"Opere II\", \"Opere III\", \"Opere IV\", \"SA\", \"TR\", \"UI\", \"FU\", \"VLC\", \"VB\", \"Conf\", \"LaP\", \"SD - VERSILIA\", \"SD\", \"VLC\", \"RAI\", \"L'A\", \"FU\", \"QP\", \"SD\",\"AG\", \"Bizz\", \"LiM\"]\n",
    "# Extract all values from archivio_counts\n",
    "all_values = set()\n",
    "for counts in archivio_counts.values():\n",
    "    all_values.update(counts.keys())\n",
    "\n",
    "# Find values that are not in specified_values\n",
    "other_values = all_values - set(specified_values)\n",
    "\n",
    "# Create DataFrames for specified values and other values\n",
    "specified_data = []\n",
    "other_data = []\n",
    "\n",
    "for archivio, counts in archivio_counts.items():\n",
    "    for value, count in counts.items():\n",
    "        if value in specified_values:\n",
    "            specified_data.append({'Value': value, 'Archivio': archivio, 'Count': count})\n",
    "        elif value in other_values:\n",
    "            other_data.append({'Value': value, 'Archivio': archivio, 'Count': count})\n",
    "\n",
    "# Create DataFrame for other values only\n",
    "df_other = pd.DataFrame(other_data)\n",
    "\n",
    "# Save DataFrame to an Excel file\n",
    "other_excel_path = '/Users/martinapensalfini/Desktop/gadda/other_values.xlsx'\n",
    "df_other.to_excel(other_excel_path, index=False)\n",
    "\n",
    "print(f\"Other Values DataFrame saved to: {other_excel_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Value  Count\n",
      "0          Quaderno    152\n",
      "1          Taccuino      5\n",
      "2            Diario      6\n",
      "3            Foglio    430\n",
      "4         Fotocopia     47\n",
      "..              ...    ...\n",
      "85  Carta da pacchi      2\n",
      "86            Album      2\n",
      "87        Biglietto      1\n",
      "88  Bozza di stampa      4\n",
      "89     Raccomandata      1\n",
      "\n",
      "[90 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "file_path = 'mergecolumntipo.json'\n",
    "\n",
    "# Read the content of the file\n",
    "with open(file_path, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Pattern to match values after \"tipo:\" within the \"Internal Description\" field\n",
    "pattern = r'tipo:\\s(.*?)(?:\\n|$)'\n",
    "\n",
    "# Extracting values matching the pattern from the \"Internal Description\" field of each item\n",
    "matches = []\n",
    "for item in json_data:\n",
    "    internal_description = item.get(\"Internal Description\", \"\")\n",
    "    match = re.findall(pattern, internal_description)\n",
    "    if match:\n",
    "        # Splitting matches by comma and adding individual elements\n",
    "        matches.extend([m.strip() for m in match[0].split(',')])\n",
    "\n",
    "# If no matches were found\n",
    "if not matches:\n",
    "    print(\"No matches found for the pattern 'tipo:' in the 'Internal Description' field.\")\n",
    "else:\n",
    "    # Counting occurrences of each value\n",
    "    value_counts = Counter(matches)\n",
    "\n",
    "    # Create a list to store DataFrame rows\n",
    "    data = [{'Value': value, 'Count': count} for value, count in value_counts.items()]\n",
    "\n",
    "    # Create a DataFrame from the list of rows\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Display the DataFrame\n",
    "    print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"tipo.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Value  Count\n",
      "0          Oggetto    435\n",
      "1      Manoscritto    446\n",
      "2           Stampa    580\n",
      "3            Bozza     19\n",
      "4   Dattiloscritto     49\n",
      "5             Foto     41\n",
      "6          Disegno      9\n",
      "7  Bozza di stampa      3\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "file_path = 'mergecolumntipo.json'\n",
    "\n",
    "# Read the content of the file\n",
    "with open(file_path, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Pattern to match values after \"tipo:\" within the \"Internal Description\" field\n",
    "pattern = r'forma:\\s(.*?)(?:\\n|$)'\n",
    "\n",
    "# Extracting values matching the pattern from the \"Internal Description\" field of each item\n",
    "matches = []\n",
    "for item in json_data:\n",
    "    internal_description = item.get(\"External Description\", \"\")\n",
    "    match = re.findall(pattern, internal_description)\n",
    "    if match:\n",
    "        # Splitting matches by comma and adding individual elements\n",
    "        matches.extend([m.strip() for m in match[0].split(',')])\n",
    "\n",
    "# If no matches were found\n",
    "if not matches:\n",
    "    print(\"No matches found for the pattern 'tipo:' in the 'Internal Description' field.\")\n",
    "else:\n",
    "    # Counting occurrences of each value\n",
    "    value_counts = Counter(matches)\n",
    "\n",
    "    # Create a list to store DataFrame rows\n",
    "    data = [{'Value': value, 'Count': count} for value, count in value_counts.items()]\n",
    "\n",
    "    # Create a DataFrame from the list of rows\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "    print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"forma.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Value  Count\n",
      "0          Quaderno    155\n",
      "1          Cartella    116\n",
      "2         Fascicolo     26\n",
      "3            Foglio    496\n",
      "4          Stampato    525\n",
      "5             Busta     72\n",
      "6      Raccoglitore      3\n",
      "7           Involto      3\n",
      "8            Volume     51\n",
      "9   Oggetto diverso    119\n",
      "10          Rubrica      3\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Path to your file containing the JSON-like data\n",
    "file_path = 'mergecolumntipo.json'\n",
    "\n",
    "# Read the content of the file\n",
    "with open(file_path, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Pattern to match values after \"tipo:\" within the \"Internal Description\" field\n",
    "pattern = r'supporto:\\s(.*?)(?:\\n|$)'\n",
    "\n",
    "# Extracting values matching the pattern from the \"Internal Description\" field of each item\n",
    "matches = []\n",
    "for item in json_data:\n",
    "    internal_description = item.get(\"External Description\", \"\")\n",
    "    match = re.findall(pattern, internal_description)\n",
    "    if match:\n",
    "        # Splitting matches by comma and adding individual elements\n",
    "        matches.extend([m.strip() for m in match[0].split(',')])\n",
    "\n",
    "# If no matches were found\n",
    "if not matches:\n",
    "    print(\"No matches found for the pattern 'tipo:' in the 'Internal Description' field.\")\n",
    "else:\n",
    "    # Counting occurrences of each value\n",
    "    value_counts = Counter(matches)\n",
    "\n",
    "    # Create a list to store DataFrame rows\n",
    "    data = [{'Value': value, 'Count': count} for value, count in value_counts.items()]\n",
    "\n",
    "    # Create a DataFrame from the list of rows\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"support.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
